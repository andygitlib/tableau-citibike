{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages & dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!usr/bin/env python3\n",
    "import os\n",
    "import shutil\n",
    "from zipfile import ZipFile \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dateutil #https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import time\n",
    "import gc  #garbage collection to free up memory\n",
    "\n",
    "# Hide warning messages in notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set some static parameters\n",
    "debug_mode = 'y'\n",
    "csv_header_ind = 'True'\n",
    "cur_dir = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "for i in range(2013,2021):\n",
    "    data_year = i\n",
    "    print(data_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_year = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-19 21:02:04.351021\n"
     ]
    }
   ],
   "source": [
    "# print start timestamp \n",
    "execStartDateTime = datetime.now()\n",
    "print(execStartDateTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = os.path.join(cur_dir,'citibike_files','raw', str(data_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try:/Users/Werd/boot_camp/gitlib/tableau-challenge/citibike_files/raw/2013/201306-citibike-tripdata.csv\n",
      "577701\n",
      "try:/Users/Werd/boot_camp/gitlib/tableau-challenge/citibike_files/raw/2013/201307-citibike-tripdata.zip\n",
      "843414\n",
      "try:/Users/Werd/boot_camp/gitlib/tableau-challenge/citibike_files/raw/2013/201308-citibike-tripdata.zip\n",
      "1001956\n",
      "try:/Users/Werd/boot_camp/gitlib/tableau-challenge/citibike_files/raw/2013/201309-citibike-tripdata.zip\n",
      "1034357\n",
      "try:/Users/Werd/boot_camp/gitlib/tableau-challenge/citibike_files/raw/2013/201310-citibike-tripdata.zip\n",
      "1037710\n",
      "try:/Users/Werd/boot_camp/gitlib/tableau-challenge/citibike_files/raw/2013/201311-citibike-tripdata.zip\n",
      "675772\n",
      "try:/Users/Werd/boot_camp/gitlib/tableau-challenge/citibike_files/raw/2013/201312-citibike-tripdata.zip\n",
      "443964\n"
     ]
    }
   ],
   "source": [
    "path = raw_dir\n",
    "\n",
    "all_files = sorted(glob.glob(os.path.join(path, \"*citibike*\")))\n",
    "\n",
    "all_df = []\n",
    "\n",
    "#parse_dates=['starttime','stoptime'],\n",
    "\n",
    "for f in all_files:\n",
    "    try: \n",
    "        print('try:' + f)\n",
    "        df = pd.read_csv(f, sep=',',header = 1,skiprows = 1,\\\n",
    "        names=['tripduration','starttime','stoptime','start station id','start station name'\\\n",
    "        ,'start station latitude','start station longitude','end station id','end station name'\\\n",
    "        ,'end station latitude','end station longitude','bikeid','usertype','birth year','gender'])\n",
    "        print(len(df.index))\n",
    "        df['a_file'] = f.split('/')[-1]    \n",
    "        all_df.append(df)\n",
    "        citibike_df = pd.concat(all_df, ignore_index=True, sort=True)\n",
    "    except:\n",
    "         print('except:' + f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing: Preview data & datatype inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a_file',\n",
       " 'bikeid',\n",
       " 'birth year',\n",
       " 'end station id',\n",
       " 'end station latitude',\n",
       " 'end station longitude',\n",
       " 'end station name',\n",
       " 'gender',\n",
       " 'start station id',\n",
       " 'start station latitude',\n",
       " 'start station longitude',\n",
       " 'start station name',\n",
       " 'starttime',\n",
       " 'stoptime',\n",
       " 'tripduration',\n",
       " 'usertype']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(citibike_df.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a_file                      object\n",
       "bikeid                       int64\n",
       "birth year                  object\n",
       "end station id             float64\n",
       "end station latitude       float64\n",
       "end station longitude      float64\n",
       "end station name            object\n",
       "gender                       int64\n",
       "start station id             int64\n",
       "start station latitude     float64\n",
       "start station longitude    float64\n",
       "start station name          object\n",
       "starttime                   object\n",
       "stoptime                    object\n",
       "tripduration                 int64\n",
       "usertype                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citibike_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set text columns as categories\n",
    "for col in ['gender', 'usertype', 'start station name', 'end station name']:\n",
    "    citibike_df[col] = citibike_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set datatypes for numeric columns\n",
    "citibike_df['start station id'] = citibike_df['start station id'].astype(str).astype(float).astype(int)\n",
    "citibike_df['start station latitude'] = citibike_df['start station latitude'].astype(float)\n",
    "citibike_df['start station latitude'] = citibike_df['start station latitude'].round(decimals=3)\n",
    "citibike_df['start station longitude'] = citibike_df['start station longitude'].astype(float)\n",
    "citibike_df['start station longitude'] = citibike_df['start station longitude'].round(decimals=3)\n",
    "citibike_df = citibike_df.dropna(subset=['end station id'])\n",
    "citibike_df['end station id'] = citibike_df['end station id'].astype(str).astype(float).astype(int)\n",
    "citibike_df['end station latitude'] = citibike_df['end station latitude'].astype(float)\n",
    "citibike_df['end station latitude'] = citibike_df['end station latitude'].round(decimals=3)\n",
    "citibike_df['end station longitude'] = citibike_df['end station longitude'].astype(float)\n",
    "citibike_df['end station longitude'] = citibike_df['end station longitude'].round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a_file                       object\n",
       "bikeid                        int64\n",
       "birth year                   object\n",
       "end station id                int64\n",
       "end station latitude        float64\n",
       "end station longitude       float64\n",
       "end station name           category\n",
       "gender                     category\n",
       "start station id              int64\n",
       "start station latitude      float64\n",
       "start station longitude     float64\n",
       "start station name         category\n",
       "starttime                    object\n",
       "stoptime                     object\n",
       "tripduration                  int64\n",
       "usertype                   category\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citibike_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_df['birth year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using try block here since data files were not consistent over time\n",
    "try:\n",
    "    if pd.api.types.is_string_dtype:\n",
    "        citibike_df['birth year'] = citibike_df['birth year'].replace({\"\\\\N\":2020})\n",
    "except:\n",
    "    print(\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_df['birth year'].fillna(2020,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that all fields are prepped drop nans in dataframe.  This is slow.\n",
    "citibike_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set birth year datatype the nans dropped\n",
    "citibike_df['birth year'] = citibike_df['birth year'].astype(str).astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "citibike_df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stamp the output files yearmonth to track the source of the data\n",
    "citibike_df['yearmonth'] =  citibike_df['a_file'].str[:6].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze by date and starthour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_df[['begindate','begintime']] = citibike_df.starttime.str.split(expand=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible optimzation:  https://stackoverflow.com/questions/50744369/how-to-speed-up-pandas-string-function\n",
    "# %timeit [x.split('~', 1)[0] for x in df['facility']]\n",
    "# def splittime(x):\n",
    "#     test = [x.split(' ', 1)[0] for x in citibike_df['starttime']]\n",
    "#     return x.map(test)\n",
    "# citibike_df['test2'] = splittime(citibike_df['starttime'])\n",
    "# TypeError: list indices must be integers or slices, not str   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pandas-dev/pandas/issues/11665\n",
    "def lookup(s):\n",
    "    \"\"\"\n",
    "    This is an extremely fast approach to datetime parsing.\n",
    "    For large data, the same dates are often repeated. Rather than\n",
    "    re-parse these, we store all unique dates, parse them, and\n",
    "    use a lookup to convert all dates.\n",
    "    \"\"\"\n",
    "    dates = {date:pd.to_datetime(date) for date in s.unique()}\n",
    "    return s.map(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_df['startdate'] = lookup(citibike_df['begindate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_df['starthour'] = citibike_df['begintime'].str.slice(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = citibike_df.groupby(['startdate']).tripduration.agg(['count','sum']).reset_index().set_index(['startdate'])\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_daily_bike_csv = os.path.join(cur_dir,'citibike_files','cleansed','citibike_trips_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode == 'n':\n",
    "    if not os.path.isfile(citibike_daily_bike_csv):\n",
    "       daily_df.to_csv(citibike_daily_bike_csv, header='column_names')\n",
    "    else: # else it exists so append without writing the header\n",
    "       daily_df.to_csv(citibike_daily_bike_csv, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend analysis tostart hour\n",
    "hourly_df = citibike_df.groupby(['startdate','starthour']).tripduration.agg(['count','sum']).reset_index()\n",
    "hourly_df.set_index('startdate', inplace = True) \n",
    "hourly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_hourly_csv = os.path.join(cur_dir,'citibike_files','cleansed','citibike_trips_hourly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode == 'n':\n",
    "    if not os.path.isfile(citibike_hourly_csv):\n",
    "       hourly_df.to_csv(citibike_hourly_csv, header='column_names')\n",
    "    else: # else it exists so append without writing the header\n",
    "       hourly_df.to_csv(citibike_hourly_csv, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze customer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "citibike_df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "citibike_df['birth year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "currentYear = datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "citibike_df['rider age'] = currentYear - citibike_df['birth year']\n",
    "citibike_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins = [-1,1,18,25,45,65,100,1000]\n",
    "citibike_df['age bracket'] = pd.cut(citibike_df['rider age'],bins)\n",
    "citibike_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customer_df = citibike_df.groupby(['startdate','gender','age bracket','usertype']).tripduration.agg(['count']).reset_index()\n",
    "customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_customer_csv = os.path.join(cur_dir,'citibike_files','cleansed','citibike_customer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode == 'n':\n",
    "    #customer_df.to_csv(citibike_customer_csv, header=csv_header_ind, mode = 'a')\n",
    "    #https://stackoverflow.com/questions/30991541/pandas-write-csv-append-vs-write\n",
    "    if not os.path.isfile(citibike_customer_csv):\n",
    "       customer_df.to_csv(citibike_customer_csv, header='column_names')\n",
    "    else: # else it exists so append without writing the header\n",
    "       customer_df.to_csv(citibike_customer_csv, mode='a', header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze bike stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_stations_df = citibike_df.drop_duplicates(subset=[\"start station id\", \"start station latitude\",\"start station longitude\",\"start station name\"])\n",
    "start_stations_df = start_stations_df[[\"start station id\", \"start station latitude\",\"start station longitude\",\"start station name\"]]\n",
    "start_stations_df = pd.DataFrame(start_stations_df)\n",
    "start_stations_df.columns = [\"station id\", \"station latitude\",\"station longitude\",\"station name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_stations_df = citibike_df.drop_duplicates(subset=[\"end station id\", \"end station latitude\",\"end station longitude\",\"end station name\"])\n",
    "end_stations_df = end_stations_df[[\"end station id\", \"end station latitude\",\"end station longitude\",\"end station name\"]]\n",
    "end_stations_df = pd.DataFrame(end_stations_df)\n",
    "end_stations_df.columns = [\"station id\", \"station latitude\",\"station longitude\",\"station name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_stations_df = start_stations_df.append(end_stations_df)\n",
    "distinct_stations_df = distinct_stations_df.drop_duplicates(subset=[\"station id\", \"station latitude\",\"station longitude\",\"station name\"])\n",
    "distinct_stations_df = distinct_stations_df.set_index('station id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_distinct_station_csv = os.path.join(cur_dir,'citibike_files','cleansed','citibike_distinct_station_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode == 'n':\n",
    "    if not os.path.isfile(citibike_distinct_station_csv):\n",
    "       start_stations_df.to_csv(citibike_distinct_station_csv, header='column_names')\n",
    "    else: # else it exists so append without writing the header\n",
    "       start_stations_df.to_csv(citibike_distinct_station_csv, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_station_trips_df = citibike_df.groupby(['startdate','start station id']).tripduration.agg(['count']).reset_index()\n",
    "start_station_trips_df = start_station_trips_df.set_index(['startdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_start_station_csv = os.path.join(cur_dir,'citibike_files','cleansed','citibike_start_station.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode == 'n':\n",
    "    if not os.path.isfile(citibike_start_station_csv):\n",
    "       start_stations_df.to_csv(citibike_start_station_csv, header='column_names')\n",
    "    else: # else it exists so append without writing the header\n",
    "       start_stations_df.to_csv(citibike_start_station_csv, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze bike equipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_equipment_df = citibike_df.groupby(['bikeid']).tripduration.agg(['count','sum']).reset_index()\n",
    "bike_equipment_df = bike_equipment_df.set_index('bikeid')\n",
    "bike_equipment_df = pd.DataFrame(bike_equipment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_date_df = citibike_df.groupby(['bikeid']).startdate.agg(['min','max']).reset_index()\n",
    "bike_date_df = bike_date_df.set_index(['bikeid'])\n",
    "bike_date_df = pd.DataFrame(bike_date_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_merged_df = pd.merge(bike_date_df, bike_equipment_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_bike_equipment_csv = os.path.join(cur_dir,'citibike_files','cleansed','citibike_bike_date.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode == 'n':\n",
    "    if not os.path.isfile(citibike_bike_equipment_csv):\n",
    "       bike_merged_df.to_csv(citibike_bike_equipment_csv, header='column_names')\n",
    "    else: # else it exists so append without writing the header\n",
    "       bike_merged_df.to_csv(citibike_bike_equipment_csv, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup memory for next run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del [[citibike_df,customer_df, distinct_stations_df,start_stations_df,end_stations_df]]\n",
    "del [[bike_equipment_df, bike_date_df, bike_merged_df]]\n",
    "gc.collect()\n",
    "citibike_df = []\n",
    "customer_df = []\n",
    "distinct_stations_df = []\n",
    "start_stations_df = []\n",
    "end_stations_df = []\n",
    "bike_equipment_df = []\n",
    "bike_date_df = []\n",
    "bike_merged_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print end \n",
    "print(data_year)\n",
    "execEndDateTime = datetime.now()\n",
    "print(execStartDateTime)\n",
    "print(execEndDateTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda952f424ed57741e293ecfe70d98884dc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
